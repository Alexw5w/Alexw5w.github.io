---
title: "交叉滞后网络"
format: html
editor: visual
---

网络分析是一种强大的手段，我们前面学习过的一些方法是基于横断面数据的，当数据类型从横断面数据扩展到纵向数据的时候，普通的网络分析方法就不再适用了。纵向数据可以理解为重复测量所得数据，分为面板数据、时间序列数据（N=1,N\>1）等多种类型。前者测量次数往往不会特别多（但样本数量大），后者则会比较多（样本数量可能小）。在此背景下，交叉滞后网络分析应运而生。

**交叉滞后网络分析**（Cross-Lagged Network Analysis，简称 CLNA）是结合**交叉滞后面板模型**（Cross-Lagged Panel Model, CLPM）与**网络分析**的一种方法，用于研究**多变量时间序列数据中变量之间的动态关系和相互影响**。它能够揭示多个变量在不同时点上的因果关系以及它们在时间上的相互依赖性。

说起来很复杂，但其实很简单，学习交叉滞后网络分析之前**，**我们先复习下 CLPM。

## 1 交叉滞后模型简介

交叉滞后模型（Cross-Lagged Panel Model，简称 **CLPM**）是一种用于分析**时间序列数据中多个变量之间的因果关系**的统计方法。它主要用于分析多个时间点上同一组变量的相互影响，特别是不同变量在不同时间点之间的**滞后效应**（即某个变量在先前时间点的变化对另一个变量在后续时间点的影响）。

### 1.1 CLPM的核心思想

-   **自回归效应（Autoregressive Effects）**：模型中的每个变量都会在自己的时间点上预测下一个时间点的值。这意味着变量会表现出一种时间上的稳定性或持续性。比如，`X1_T2 ~ X1_T1` 表示变量 X1 在时间点 T2 的值由 X1 在时间点 T1 的值预测。

-   **交叉滞后效应（Cross-Lagged Effects）**：模型中的某些变量不仅仅影响自己的未来值，还可以影响其他变量在未来的值。比如，`X2_T2 ~ X1_T1` 表示 X1 在时间点 T1 对 X2 在时间点 T2 的影响。

-   **同时相关性（Concurrent Correlation）**：同一时间点上的不同变量之间可能会存在相关性，但这不是 CLPM 研究的主要焦点，CLPM 更加关注**滞后的因果关系**。

### 1.2 CLPM的优点

-   **因果推断**：CLPM 允许对多个时间点上的数据进行分析，帮助理解一个变量的变化是否会导致另一个变量在未来的变化。
-   **双向分析**：CLPM 可以同时研究两个变量之间的双向影响，例如研究 A 对 B 的影响，同时也能分析 B 对 A 的影响。
-   **控制自相关**：CLPM 控制了变量本身的时间序列自相关性，减少了混淆因果关系的可能性。

### 1.3 CLPM模型示例

假设我们有两个变量 `X` 和 `Y`，在两个时间点 `T1` 和 `T2` 上进行测量，CLPM 模型会如下描述：

-   `X_T2 ~ X_T1`：表示 `X` 在时间点 `T1` 对时间点 `T2` 的预测。
-   `Y_T2 ~ Y_T1`：表示 `Y` 在时间点 `T1` 对时间点 `T2` 的预测。
-   `X_T2 ~ Y_T1`：表示 `Y` 在时间点 `T1` 对 `X` 在时间点 `T2` 的预测（交叉滞后效应）。
-   `Y_T2 ~ X_T1`：表示 `X` 在时间点 `T1` 对 `Y` 在时间点 `T2` 的预测（交叉滞后效应）。

我们可以使用 `lavaan` 包来拟合交叉滞后面板模型，当然也可以用其他软件。

![](images/简单交叉滞后模型.png){fig-align="center"}

## 2 交叉滞后网络分析

### 2.1 核心概念

交叉滞后网络分析通过**网络图**直观地展示各个变量在不同时间点上的相互作用，强调变量之间的**双向影响**（即滞后影响）。该方法有助于研究不同时间点上的变量如何相互作用，并能够捕捉变量之间的**交叉滞后效应**。

-   **自回归效应（Autoregressive Effects）**：描述同一变量在不同时间点之间的关系。例如，某一变量在 `T1` 时间点的状态对该变量在 `T2` 时间点的状态的影响。

-   **交叉滞后效应（Cross-Lagged Effects）**：描述一个变量在 `T1` 时间点的状态如何影响另一个变量在 `T2` 时间点的状态。这可以揭示两个变量之间的滞后因果关系。

-   **网络结构**：在网络图中，节点代表不同的变量，边表示这些变量之间的相互关系。边的方向表示因果顺序（如 `T1` 的一个变量影响 `T2` 的另一个变量），边的粗细或颜色可以表示影响的强度或显著性。

### 2.2 主要步骤

-   **数据准备**：你需要时间序列数据，其中包括多个变量在至少两个时间点的观测。例如，8 个变量在两个时间点上的测量数据，表示为 `X1_T1`, `X1_T2`, \..., `X8_T1`, `X8_T2`。

-   **拟合模型**：采用交叉滞后模型（CLPM），估计变量之间的滞后效应和自回归效应。

-   **构建网络**：基于模型的参数估计，构建反映各个变量之间关系的网络图。可以将滞后效应和自回归效应表示为不同的边，边的方向和权重根据估计的系数确定。

-   **网络分析与可视化**：使用网络分析工具（如 `qgraph`）来绘制网络图并分析变量之间的关系。可以通过网络图直观地观察哪些变量在时间上对其他变量有较强的影响

### 3 R语言实现

一些文献作者和博主将这块内容写得比较复杂，是因为他们做了很多全面或细节的工作，在这里，我只关注核心的部分。通俗点说，就是干了三件事：估计交叉滞后关系；拟合网络模型；计算中心性。其他的没有展示，如果你确实有需要，可以联系我，也可以查阅其他资料。我的运行环境见文末，可以先看看，避免因版本问题出现不兼容现象。

#### 3.1 加载包和数据集

加载包，glmnet是本次估计交叉滞后模型的核心工具，qgraph用于估计和可视化网络模型，没有安装的请先安装。

```{r}
#| label: load-packages
#| include: false

library(glmnet) 
library(qgraph) 
```

加载数据集：本次使用的数据来自mplus，是一份在线公开的数据，我对其变量进行了微调，处理后的数据包含4个变量，每个变量共测量两次。

```{r}
myData = read.table('https://www.statmodel.com/usersguide/chap9/ex9.36.dat',col.names = c(
  "x1_T1", "x2_T1", "x3_T1", "x4_T1",  
  "x1_T2", "x2_T2", "x3_T2", "x4_T2",'other'))
myData = myData[1:500,1:8]
head(myData)
```

#### 3.2 使用glmnet估计交叉滞后模型

这是关键点，先上代码，然后再解释为何可以这样做。

```{r}
# 指定变量个数
k = 4
# 构建空白矩阵，等下要用它来填补glmnet回归获得的系数
input = matrix(0, k, k) 

# 自建for循环
# 以前一时间点测量的所有变量数据为自变量，分别对下一个时间点的变量进行正则化回归，然后提取每个回归方程的回归系数，放入我们构建好的空白矩阵input
for (i in 1:k){
  set.seed(666)
  cv_fit = cv.glmnet(as.matrix(myData[,1:k]), myData[,(k+i)], alpha = 1, standardize=T)
  best_lambda = cv_fit$lambda.min
  input[1:k,i] = coef(cv_fit, s = best_lambda, exact = F)[2:(k+1)]
  print(best_lambda)
}
input
```

3.3 拟合网络模型

```{r}
g1 = qgraph(input,layout = "spring",details = T) #也可以自己调整颜色，如color="gold",edge.color='pink')

```

#### 3.4 去除自回归

如果你不想要展示自回归，可以设置输入矩阵的对角线（自回归）为0。

```{r}
# 去除自回归效应
# copy一份矩阵
noauotreg_input= input

# 将矩阵的对角线元素设置为0
diag(noauotreg_input) = 0

# 查看新矩阵
noauotreg_input
```

估计新模型：

```{r}
g2 = qgraph(noauotreg_input,layout = "spring",details = T,color="gold")
```

#### 3.5 计算中心性

```{r}
centrality(g1)
```

可视化：

```{r}
centralityPlot(g1, include=c("OutStrength", "InStrength", 
                             "Betweenness","Closeness"))
```

是不是非常简单？哈哈，毕竟错失了很多细节部分，所以会显得很简单。解释一下这个原理：

前面以前说过了，交叉滞后模型的核心就是自回归和交叉滞后效应，这是通过多次回归实现的，常规思路是使用lavaan包处理（如果你用R的话），但网络分析一般是在复杂场景中进行了，变量数较多，所以通常会使用正则化的回归技术来计算这几种核心的效应值。

正如我在代码注释中提到的，以前一个时间点的所有变量为x，分别以下一个时间点的变量为y（一个个来），依次建立回归模型，为了避免模型过于复杂，也为了减轻网络效应值很小的"虚假"的边，我们可以用L1正则化（lasso）技术来将一些比较小的系数给压缩为0，这样可以实现网络的稀疏化。

然后，我们可以把得到的各回归系数存储在矩阵内，然后将其输入qgraph函数（也可以是别的）。

### 4 小结与建议

交叉滞后网络模型是最常见的纵向网络分析方法之一，但一般不适用于重复次数非常多的场景，比如生态瞬时数据或者密集追踪数据，这个就需要应用到一种叫做向量自回归（VAR及其变体）的技术了，这些会在后续介绍。

本次仅做了一个非常简单的建模演示，如果你想要更进一步了解此类模型，建议掌握其中的原理，这样后续想继续做点什么就方便很多了。兴趣是最好的老师，高质量文献是最好的学习途径，辅助使用一些人工智能工具，往往可以事半功倍。欢迎关注我们的公众号：护理统计随笔，会不定期更新一些新的进展。

最后，交叉滞后网络分析中是可以加入协变量的，就在glmnet循环部分加入，计算其系数，后面可以再剔除。

**运行环境：**

```{r}
sessionInfo()
```
